# Entrenamiento del Ingeniero de Carrera

Gu√≠a completa para entrenar el agente ingeniero que toma decisiones estrat√©gicas sobre pit stops y gesti√≥n de neum√°ticos.

---

## üìã √çndice

- [¬øQu√© es el Ingeniero?](#qu√©-es-el-ingeniero)
- [Algoritmo DQN](#algoritmo-dqn)
- [C√≥mo Entrenar](#c√≥mo-entrenar)
- [C√≥mo Evaluar](#c√≥mo-evaluar)
- [Comparaci√≥n de Estrategias](#comparaci√≥n-de-estrategias)

---

## ¬øQu√© es el Ingeniero?

El **Engineer Agent** es responsable de la **estrategia de carrera**:

### Decisiones que Toma

1. **Cu√°ndo hacer pit stop**
   - Monitorea desgaste de neum√°ticos
   - Eval√∫a tiempo restante de carrera
   - Decide momento √≥ptimo para parar

2. **Qu√© compuesto de neum√°tico usar**
   - **Soft**: R√°pidos pero se desgastan r√°pido
   - **Medium**: Equilibrados
   - **Hard**: Duraderos pero m√°s lentos

3. **Gesti√≥n de la carrera**
   - Planifica n√∫mero de pit stops
   - Optimiza tiempo total de carrera
   - Balancea velocidad vs durabilidad

### Espacio de Acciones

El ingeniero tiene **4 acciones discretas**:

```
0: Continue (no pit)
1: Pit - Soft tyres
2: Pit - Medium tyres
3: Pit - Hard tyres
```

### Observaciones

El ingeniero observa:
- Desgaste actual de neum√°ticos (%)
- Vuelta actual
- Vueltas totales
- Velocidad del coche
- Posici√≥n en pista
- Compuesto actual de neum√°tico

---

## Algoritmo DQN

El ingeniero usa **DQN (Deep Q-Network)** para aprender la estrategia √≥ptima.

### DQN (Deep Q-Network)

**Tipo:** Off-policy, Value-based, Discrete actions

#### Caracter√≠sticas

| Aspecto | Valoraci√≥n | Detalles |
|---------|-----------|----------|
| **Estabilidad** | ‚≠ê‚≠ê‚≠ê‚≠ê | Bastante estable con experience replay |
| **Velocidad** | ‚≠ê‚≠ê‚≠ê | Convergencia moderada |
| **Facilidad de uso** | ‚≠ê‚≠ê‚≠ê‚≠ê | Sencillo de configurar |
| **Sample efficiency** | ‚≠ê‚≠ê‚≠ê‚≠ê | Buena (off-policy con replay buffer) |
| **Mejor para** | Acciones discretas | Pit/no pit, tipo de neum√°tico |

#### Pros
- ‚úÖ **Ideal para decisiones discretas**: Perfecto para el rol del ingeniero
- ‚úÖ **Sample efficient**: Reutiliza experiencia con replay buffer
- ‚úÖ **Estable**: Experience replay reduce correlaci√≥n
- ‚úÖ **Interpretable**: Q-values muestran valor de cada acci√≥n

#### Cons
- ‚ö†Ô∏è **Solo acciones discretas**: No puede usarse para control continuo
- ‚ö†Ô∏è **Requiere exploration**: Epsilon-greedy para balance exploraci√≥n/explotaci√≥n
- ‚ö†Ô∏è **Convergencia m√°s lenta que DQN moderno**: Rainbow DQN ser√≠a mejor pero m√°s complejo

#### Por Qu√© DQN para el Ingeniero

1. **Acciones discretas naturales**: Pit/no pit es binario, tipo de neum√°tico es categ√≥rico
2. **Horizonte largo**: Decisiones estrat√©gicas a lo largo de toda la carrera
3. **Sample efficiency importante**: Las carreras son largas, queremos aprender r√°pido
4. **Estabilidad**: Decisiones cr√≠ticas requieren pol√≠tica confiable

---

## C√≥mo Entrenar

### Entrenamiento B√°sico

```bash
python scripts/train_engineer.py \
    --track monza \
    --timesteps 500000
```

**Esto crea:**
- Modelo entrenado: `trained_models/engineer_final_monza.zip`
- Checkpoints: `trained_models/engineer_checkpoint_*.zip`
- Logs (si `--tensorboard`): `logs/`

### Opciones de Entrenamiento

#### 1. Circuito Espec√≠fico

```bash
python scripts/train_engineer.py \
    --track monza \
    --timesteps 500000
```

#### 2. Con TensorBoard

```bash
python scripts/train_engineer.py \
    --track monza \
    --timesteps 500000 \
    --tensorboard
```

**Monitorear:**
```bash
tensorboard --logdir logs/
```

#### 3. Configuraci√≥n Personalizada

```bash
python scripts/train_engineer.py \
    --track monza \
    --timesteps 1000000 \
    --learning-rate 1e-4 \
    --save-freq 50000
```

#### 4. Continuar Entrenamiento

```bash
# Entrenar primero
python scripts/train_engineer.py \
    --track monza \
    --timesteps 250000 \
    --model-dir models/stage1/

# Continuar desde checkpoint
python scripts/train_engineer.py \
    --track monza \
    --timesteps 500000 \
    --load-model models/stage1/engineer_checkpoint_250000.zip \
    --model-dir models/stage2/
```

---

### Argumentos Disponibles

```bash
python scripts/train_engineer.py \
    --track NAME \              # Nombre del circuito
    --timesteps N \             # Timesteps totales de entrenamiento
    --learning-rate LR \        # Learning rate (default: 1e-4)
    --save-freq N \             # Guardar checkpoint cada N steps
    --tensorboard \             # Habilitar logging a TensorBoard
    --device {cpu,cuda,auto}    # Dispositivo (default: cpu)
```

### Hiperpar√°metros Recomendados

```bash
# Standard (recomendado)
--learning-rate 1e-4
--timesteps 500000

# Entrenamiento r√°pido
--learning-rate 3e-4
--timesteps 250000

# Entrenamiento completo
--learning-rate 1e-4
--timesteps 1000000
```

---

## C√≥mo Evaluar

### Evaluaci√≥n B√°sica

```bash
python scripts/evaluate.py \
    --model trained_models/engineer_final_monza.zip \
    --track tracks/monza.json \
    --episodes 10
```

**Salida:**
- M√©tricas de rendimiento
- Decisiones de pit stop por episodio
- Gesti√≥n de neum√°ticos
- JSON report y plots

### Evaluaci√≥n Detallada

```bash
python scripts/evaluate.py \
    --model trained_models/engineer_final_monza.zip \
    --track tracks/monza.json \
    --episodes 20 \
    --output results/engineer/ \
    --record
```

### M√©tricas Importantes para el Ingeniero

Al evaluar, presta atenci√≥n a:

1. **Completion Rate** - ¬øEl ingeniero completa carreras?
2. **Tyre Wear per Lap** - ¬øGestiona bien el desgaste?
3. **Lap Times** - ¬øLas decisiones mejoran tiempos?
4. **Pit Stop Timing** - ¬øHace pit en momentos √≥ptimos?

---

## Comparaci√≥n de Estrategias

### Entrenar M√∫ltiples Estrategias

Puedes entrenar con diferentes configuraciones y comparar:

```bash
#!/bin/bash
# train_engineer_strategies.sh

TRACK="monza"

# Estrategia conservadora (learning rate bajo)
python scripts/train_engineer.py \
    --track "$TRACK" \
    --timesteps 500000 \
    --learning-rate 5e-5 \
    --model-dir models/engineer_conservative/

# Estrategia agresiva (learning rate alto)
python scripts/train_engineer.py \
    --track "$TRACK" \
    --timesteps 500000 \
    --learning-rate 3e-4 \
    --model-dir models/engineer_aggressive/

# Estrategia balanced (standard)
python scripts/train_engineer.py \
    --track "$TRACK" \
    --timesteps 500000 \
    --learning-rate 1e-4 \
    --model-dir models/engineer_balanced/
```

### Evaluar Estrategias

```bash
#!/bin/bash
# evaluate_engineer_strategies.sh

TRACK="tracks/monza.json"
EPISODES=20

for strategy in conservative aggressive balanced; do
    python scripts/evaluate.py \
        --model "models/engineer_${strategy}/engineer_final_monza.zip" \
        --track "$TRACK" \
        --episodes "$EPISODES" \
        --output "results/engineer_${strategy}/"
done
```

### Comparar Directamente

```bash
# Conservative vs Aggressive
python scripts/evaluate.py \
    --model models/engineer_conservative/engineer_final_monza.zip \
    --compare models/engineer_aggressive/engineer_final_monza.zip \
    --track tracks/monza.json \
    --episodes 20

# Balanced vs Aggressive
python scripts/evaluate.py \
    --model models/engineer_balanced/engineer_final_monza.zip \
    --compare models/engineer_aggressive/engineer_final_monza.zip \
    --track tracks/monza.json \
    --episodes 20
```

---

## Workflow Completo: Piloto + Ingeniero

### Entrenar Ambos Agentes

```bash
#!/bin/bash
# train_both_agents.sh

TRACK_NAME="monza"
TRACK_PATH="tracks/monza.json"

# 1. Entrenar Piloto
echo "Entrenando piloto..."
python scripts/train_pilot.py \
    --algorithm PPO \
    --track "$TRACK_PATH" \
    --total-timesteps 500000 \
    --model-dir models/pilot/

# 2. Entrenar Ingeniero
echo "Entrenando ingeniero..."
python scripts/train_engineer.py \
    --track "$TRACK_NAME" \
    --timesteps 500000 \
    --model-dir models/engineer/

echo "Entrenamiento completo!"
```

### Evaluar Ambos Agentes

```bash
#!/bin/bash
# evaluate_both_agents.sh

TRACK_PATH="tracks/monza.json"
EPISODES=20

# Evaluar piloto
echo "Evaluando piloto..."
python scripts/evaluate.py \
    --model models/pilot/PPO_monza_final.zip \
    --track "$TRACK_PATH" \
    --episodes "$EPISODES" \
    --output results/pilot/

# Evaluar ingeniero
echo "Evaluando ingeniero..."
python scripts/evaluate.py \
    --model models/engineer/engineer_final_monza.zip \
    --track "$TRACK_PATH" \
    --episodes "$EPISODES" \
    --output results/engineer/

echo "Evaluaci√≥n completa!"
echo "Resultados en: results/"
```

---

## An√°lisis de Decisiones del Ingeniero

### Script: Analizar Pit Stops

```python
#!/usr/bin/env python3
"""
analyze_pit_strategy.py

Analiza las decisiones de pit stop del ingeniero.
"""

import json
from pathlib import Path

# Cargar resultados
results_file = Path("results/engineer/engineer_final_monza_evaluation.json")

with open(results_file, 'r') as f:
    data = json.load(f)

# Analizar por episodio
print("="*60)
print("AN√ÅLISIS DE ESTRATEGIA DE PIT STOPS")
print("="*60)

for ep in data['per_episode']:
    episode_num = ep['episode']
    laps = ep['laps_completed']
    lap_times = ep.get('lap_times', [])

    print(f"\nEpisodio {episode_num}:")
    print(f"  Vueltas completadas: {laps}")

    if lap_times:
        print(f"  Lap times: {[f'{t:.2f}s' for t in lap_times]}")
        print(f"  Mejor vuelta: {min(lap_times):.2f}s")
        print(f"  Promedio: {sum(lap_times)/len(lap_times):.2f}s")

# M√©tricas generales
metrics = data['metrics']
print(f"\n{'='*60}")
print("M√âTRICAS GENERALES")
print(f"{'='*60}")
print(f"Tasa de finalizaci√≥n: {metrics['completion_rate']:.1%}")
print(f"Desgaste por vuelta: {metrics['tyre_wear_per_lap_mean']:.1f}%")
print(f"Reward promedio: {metrics['total_reward_mean']:.2f}")
```

---

## Estrategias de Neum√°ticos

### Tipos de Compuesto

| Compuesto | Velocidad | Durabilidad | Cu√°ndo Usar |
|-----------|-----------|-------------|-------------|
| **Soft** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | Sprint final, qualifying, pocos laps restantes |
| **Medium** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Equilibrio, stint medio de carrera |
| **Hard** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Stint largo, inicio de carrera, minimizar pit stops |

### Estrategias Comunes

#### 1-Stop Strategy
```
Start: Hard ‚Üí Lap 15: Soft ‚Üí Finish
```
- Una sola parada
- Hard para aguantar, Soft para sprint final

#### 2-Stop Strategy
```
Start: Soft ‚Üí Lap 8: Medium ‚Üí Lap 16: Soft ‚Üí Finish
```
- Dos paradas
- Mantiene ritmo alto toda la carrera
- M√°s tiempo perdido en pits

#### No-Stop Strategy
```
Start: Hard ‚Üí Finish (no pit)
```
- Cero paradas
- Solo viable en carreras cortas
- Requiere gesti√≥n agresiva del desgaste

---

## üí° Tips para el Ingeniero

1. **Entrena suficiente tiempo** - El ingeniero necesita aprender timing de pit stops (500k-1M timesteps)
2. **Monitorea decisiones** - Usa TensorBoard para ver cu√°ndo hace pit stops
3. **Eval√∫a en carreras largas** - Estrategia se nota mejor con m√°s vueltas (`--max-laps 10`)
4. **Compara con baseline** - Eval√∫a contra estrategia simple (e.g., pit en lap 10)
5. **Learning rate conservador** - 1e-4 funciona bien para decisiones estrat√©gicas
6. **Paciencia** - DQN tarda m√°s en converger que algoritmos continuos

---

## üîç Debugging

### El ingeniero no hace pit stops

**Posibles causas:**
- Reward function no penaliza suficiente desgaste alto
- Learning rate muy bajo
- No ha entrenado suficiente

**Soluci√≥n:**
```bash
# Entrenar m√°s tiempo con learning rate mayor
python scripts/train_engineer.py \
    --timesteps 1000000 \
    --learning-rate 3e-4
```

### Hace demasiados pit stops

**Posibles causas:**
- Reward function penaliza demasiado desgaste
- Exploration rate muy alto

**Soluci√≥n:**
- Ajustar reward function en el c√≥digo
- Entrenar m√°s para que converja

### Lap times inconsistentes

**Posible causa:**
- Decisiones de neum√°ticos no √≥ptimas

**Soluci√≥n:**
- Entrenar m√°s tiempo
- Evaluar que el piloto funcione bien primero

---

## üìö Referencias

- [Evaluation Guide](../docs/EVALUATION_GUIDE.md) - C√≥mo evaluar modelos
- [TRAIN_PILOT.md](TRAIN_PILOT.md) - Entrenamiento del piloto
- [Scripts README](README.md) - Documentaci√≥n principal
- [DQN Paper](https://arxiv.org/abs/1312.5602) - Art√≠culo original de DQN

---

**¬°Buena suerte con tu ingeniero de carrera! üèéÔ∏èüîß**
